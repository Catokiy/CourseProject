{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16cacc01",
   "metadata": {
    "id": "16cacc01"
   },
   "source": [
    "# ИД22-2, Кирюшкин Николай, КП\n",
    "\n",
    " Датасет - https://www.kaggle.com/datasets/suchintikasarkar/sentiment-analysis-for-mental-health/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22381b78",
   "metadata": {
    "id": "22381b78"
   },
   "source": [
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d3daba",
   "metadata": {
    "id": "b7d3daba"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "%matplotlib inline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from wordcloud import WordCloud\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eCAlaZFus_Bl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCAlaZFus_Bl",
    "outputId": "715c887b-1ad8-4799-f4a6-ea99b8443cfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kkiry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('popular')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f07ab9",
   "metadata": {
    "id": "39f07ab9"
   },
   "source": [
    "### Чтение и описание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c72f7a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0c72f7a2",
    "outputId": "04a0c561-a092-468d-db3e-ca2fe094c847"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement   status\n",
       "0                                         oh my gosh  Anxiety\n",
       "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Combined Data.csv', encoding=\"utf-8\", index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3c3788",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "5d3c3788",
    "outputId": "aad12201-d153-45e3-fcbb-8193f9df8d77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52681</td>\n",
       "      <td>53043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>51073</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>what do you mean?</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22</td>\n",
       "      <td>16351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                statement  status\n",
       "count               52681   53043\n",
       "unique              51073       7\n",
       "top     what do you mean?  Normal\n",
       "freq                   22   16351"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d02671",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19d02671",
    "outputId": "03e8a93a-9b22-4bbd-d861-b86b42fe0edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53043 entries, 0 to 53042\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   statement  52681 non-null  object\n",
      " 1   status     53043 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07d73ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f07d73ee",
    "outputId": "2d427045-620f-4193-8ccd-cede39e47d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенные значения:\n",
      "statement    362\n",
      "status         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Пропущенные значения:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0862b0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "f0862b0f",
    "outputId": "49e1399a-a64f-4701-ea9d-98d93a4dc5c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statement    0\n",
       "status       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44fa0a",
   "metadata": {
    "id": "9d44fa0a"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b48e62",
   "metadata": {
    "id": "63b48e62"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Приведение текста к нижнему регистру\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)  # Удаление markdown-ссылок\n",
    "    text = re.sub(r'@\\w+', '', text)  # Удаление упоминаний (handle)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Удаление ссылок\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Удаление HTML-тегов\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Удаление знаков препинания\n",
    "    text = re.sub(r'\\n', '', text)  # Удаление символов новой строки\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Удаление слов с цифрами\n",
    "    return text.strip()  # Удаление лишних пробелов в начале и конце текста\n",
    "\n",
    "df['preprocessed_statement'] = df.statement.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6f035",
   "metadata": {
    "id": "d6e6f035"
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df.preprocessed_statement.apply(lambda x: [i for i in word_tokenize(x)])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    \n",
    "    pos_tagged = nltk.pos_tag(tokens) \n",
    "\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else: \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "df['lemmatized_tokens'] = df['tokens'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0ed4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "60d0ed4b",
    "outputId": "376d71f8-be71-494a-c020-de5967792509"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3447413",
   "metadata": {
    "id": "a3447413"
   },
   "source": [
    "### Добавление новых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7410160",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "b392e0f7",
    "outputId": "68dfa679-df16-433f-9f9f-ff8f34d1ca75"
   },
   "outputs": [],
   "source": [
    "df['statement_len'] = df.statement.apply(len)\n",
    "df['pronoun_count'] = df.lemmatized_tokens.apply(lambda x: len([i for i in x.split() if i in ['i','ive','im','i`m','i`ve']]))\n",
    "df['word_count'] = df.statement.apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "df['sentence_count'] = df.statement.apply(lambda x: len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yrIzjngG0HdM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "yrIzjngG0HdM",
    "outputId": "0ad2e151-7adf-4851-9bde-946f02eb486e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5f4c7",
   "metadata": {
    "id": "e9d5f4c7"
   },
   "source": [
    "### Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b30ee0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "30b30ee0",
    "outputId": "893defe3-504b-4c9a-c317-9cc14b221841"
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1,\n",
    "              subplot_titles=(\"С выбросами\", \"Очищено от выбросов\"))\n",
    "\n",
    "fig.add_trace(go.Histogram(x=df.statement_len),row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "Q1 = df.statement_len.quantile(0.25)\n",
    "Q3 = df.statement_len.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "filtered_df = df[(df.statement_len >= lower_bound) & (df.statement_len <= upper_bound)]\n",
    "fig.add_trace(go.Histogram(x=filtered_df.statement_len),row=2, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=600, width=800, title_text=\"Распределение длинны текста\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b760f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "916b760f",
    "outputId": "285a00d8-e76a-44fe-aabb-e77f1c5a3249"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df.status,\n",
    "                           y=df.statement_len,\n",
    "                           histfunc='avg',\n",
    "                           name=\"Средняя длина сообщения\",\n",
    "                           text=round(df.groupby('status').statement_len.mean())))\n",
    "\n",
    "fig.add_trace(go.Histogram(x=df.status,\n",
    "                           y=df['statement'].apply(lambda x: len(nltk.sent_tokenize(x))),\n",
    "                           histfunc='avg',\n",
    "                           name=\"Среднее кол-во предложений\",\n",
    "                           text=round(df.groupby('status').word_count.mean())))\n",
    "\n",
    "fig.add_trace(go.Histogram(x=df.status,\n",
    "                           y=df['statement'].apply(lambda x: len(nltk.word_tokenize(x))),\n",
    "                           histfunc='avg',\n",
    "                           name=\"Среднее кол-во слов\",\n",
    "                           text=round(df.groupby('status').sentence_count.mean())))\n",
    "                           \n",
    "fig.add_trace(go.Histogram(x=df.status,\n",
    "                           y=df.pronoun_count,\n",
    "                           histfunc='avg',\n",
    "                           name=\"Среднее кол-во местоимений\",\n",
    "                           text=round(df.groupby('status').pronoun_count.mean())))\n",
    "fig.update_layout(\n",
    "    yaxis_type='log',  # Логарифмическая шкала\n",
    "    title='Сравнение дигнозов по численным метрикам',\n",
    "    xaxis_title='Диагноз',\n",
    "    yaxis_title='Средние значения (логарифмическая шкала)',\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # Горизонтальное расположение легенды\n",
    "        yanchor=\"bottom\",  # Привязка к нижней части легенды\n",
    "        y=1.02,  # Расположить над графиком\n",
    "        xanchor=\"center\",  # Центрирование\n",
    "        x=0.5  # Легенда посередине\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    xaxis=dict(\n",
    "        categoryorder='array',  # Указываем пользовательский порядок\n",
    "        categoryarray=['Anxiety', 'Bipolar', 'Depression', 'Normal', 'Personality disorder',\n",
    "       'Stress', 'Suicidal'],  # Порядок категорий\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05346f6b",
   "metadata": {
    "id": "05346f6b"
   },
   "source": [
    "Из графика видно что в среднем длинна текста, количество слов и предложений кратно выше при наличии психического растройства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfa055",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "2cbfa055",
    "outputId": "5603c46e-bcf3-4f1a-fa43-c6a648bf7824",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='status', title='Распределение диагнозов ментальных заболеваний', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e3c50",
   "metadata": {
    "id": "fb4e3c50"
   },
   "source": [
    "В распределении классов наблюдается сильный дисбаланс который необходимо учесть при проектировании модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32055f2c",
   "metadata": {
    "id": "32055f2c"
   },
   "source": [
    "### Облака слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1e49b",
   "metadata": {
    "id": "4ef1e49b"
   },
   "outputs": [],
   "source": [
    "def plot_wordcloud(tokens, status):\n",
    "    wordcloud = WordCloud(width=1600, height=1000, background_color='white').generate(tokens)\n",
    "    ax[i,j].imshow(wordcloud, interpolation='bilinear')\n",
    "    ax[i,j].set_title(f'{status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf07ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e5bf07ef",
    "outputId": "68a92827-6e29-4d5e-ec57-9df1671e163a"
   },
   "outputs": [],
   "source": [
    "statuses = df['status'].unique()\n",
    "fig, ax = plt.subplots(4, 2)\n",
    "fig.set_figheight(25)\n",
    "fig.set_figwidth(18)\n",
    "i, j=0, 0\n",
    "plot_wordcloud(' '.join(df['tokens'].apply(lambda x: ' '.join(x)).tolist()), 'All statuses')\n",
    "\n",
    "\n",
    "for status in statuses:\n",
    "    if j<1: j+=1\n",
    "    elif j==1 and i<3:\n",
    "        j=0\n",
    "        i+=1\n",
    "\n",
    "    tokens_data = ' '.join(df[df['status'] == status]['tokens'].apply(lambda x: ' '.join(x)).tolist())\n",
    "    plot_wordcloud(tokens_data, status)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748122a2",
   "metadata": {
    "id": "748122a2"
   },
   "source": [
    "### Подготовка тренировочной и обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982cb26",
   "metadata": {
    "id": "d982cb26"
   },
   "outputs": [],
   "source": [
    "X = df[['statement_len','pronoun_count','lemmatized_tokens']]\n",
    "y = df.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885369d5",
   "metadata": {
    "id": "885369d5"
   },
   "outputs": [],
   "source": [
    "lbl_enc = LabelEncoder()\n",
    "y = lbl_enc.fit_transform(y.values)\n",
    "labels = lbl_enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b627008",
   "metadata": {
    "id": "9b627008"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f816d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73f816d3",
    "outputId": "1d40f165-8d60-4f2c-cbca-b098436d4ffd"
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97344307",
   "metadata": {
    "id": "97344307"
   },
   "outputs": [],
   "source": [
    "# Преобразование текста в числовые признаки с помощью TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['lemmatized_tokens'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['lemmatized_tokens'])\n",
    "\n",
    "X_train_num = X_train[['statement_len','pronoun_count']].values\n",
    "X_test_num = X_test[['statement_len','pronoun_count']].values\n",
    "\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_num])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf84d0",
   "metadata": {
    "id": "5ccf84d0"
   },
   "source": [
    "### Оверсемплинг тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078b3f5",
   "metadata": {
    "id": "a078b3f5"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b407b21",
   "metadata": {
    "id": "2b407b21"
   },
   "source": [
    "### Поиск лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b7850",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d5b7850",
    "outputId": "a4244601-9110-4510-fb64-c2dfdc95e3e6"
   },
   "outputs": [],
   "source": [
    "# Определение моделей\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Гиперпараметры для поиска\n",
    "param_grid = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear'],\n",
    "        'penalty': [None, 'l1','l2']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [3, 5, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'alpha': [0.01, 0.1, 1]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'min_child_weight': [1, 3, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Выбор модели и настройка гиперпараметров с помощью GridSearchCV\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Настройка гиперпараметров для модели: {model_name}\")\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid[model_name], cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    best_models[model_name] = [grid_search.best_estimator_]\n",
    "    print(f\"Лучшие гиперпараметры для {model_name}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Оценка модели на тестовых данных\n",
    "    y_pred = grid_search.predict(X_test_combined)\n",
    "    print(f\"Результаты классификации для {model_name}:\\n{classification_report(y_test, y_pred, target_names=labels)}\")\n",
    "    print(\"-\" * 80)\n",
    "    best_models[model_name].append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame({name:{'Accuracy': val[0].score(X_test_combined, y_test),\n",
    "                                    'Precision': precision_score(y_test, val[1],average='macro'),\n",
    "                                    'Recall': recall_score(y_test, val[1],average='macro'),\n",
    "                                    'F1 score': f1_score(val[1],y_test,average='macro'),\n",
    "#                                     'ROC AUC score': roc_auc_score(y_test, val[1], average='macro', multi_class='ovr')\n",
    "                                   } for name, val in best_models.items()})\n",
    "sns.heatmap(model_results,annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418621a",
   "metadata": {
    "id": "1418621a"
   },
   "source": [
    "### Оценка метрик полученной модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcea24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17fcea24",
    "outputId": "7e2aae8b-4dd7-4aaf-ccdf-65de9a9e5aec"
   },
   "outputs": [],
   "source": [
    "# Определение наилучшей модели\n",
    "best_model_name = max(best_models, key=lambda x: f1_score(y_test, best_models[x][0].predict(X_test_combined), average='macro'))\n",
    "print(f\"Наилучшая модель: {best_model_name}\")\n",
    "\n",
    "# Оценка наилучшей модели\n",
    "best_model = best_models[best_model_name][0]\n",
    "y_pred_best = best_model.predict(X_test_combined)\n",
    "print(f\"Результаты наилучшей модели ({best_model_name}):\\n{classification_report(y_test, y_pred_best, target_names=labels)}\")\n",
    "f1_score(y_test, best_model.predict(X_test_combined), average='macro'),best_model.score(X_test_combined,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e950b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "eb7e950b",
    "outputId": "db236648-5449-461f-f23b-4da1c4196d04"
   },
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef87d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53ef87d3",
    "outputId": "4a659858-808c-493b-d8b7-2a01253b205b"
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1_macro']\n",
    "scores = cross_validate(best_model, X_test_combined, y_test, cv=10, scoring=scoring)\n",
    "\n",
    "fpr, tpr, treshold = roc_curve(y_test, best_model.predict_proba(X_test_combined)[:,1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"Метрики полученной модели\")\n",
    "print('Accuracy:', scores['test_accuracy'].mean())\n",
    "print('F1-score:', scores['test_f1_macro'].mean())\n",
    "print('ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436d31b",
   "metadata": {
    "id": "5436d31b"
   },
   "source": [
    "### Визуализация результатов модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793837d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "1793837d",
    "outputId": "f6bf6b84-26ce-4ce8-fe8b-d95fdd88b740"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Предсказанные')\n",
    "plt.ylabel('Действительные')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77049f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "c77049f3",
    "outputId": "26691989-b4be-42bd-fa51-f100bdd3875f"
   },
   "outputs": [],
   "source": [
    "y_scores = best_model.predict_proba(X_test_combined)\n",
    "y_onehot = pd.get_dummies(y_test, columns=best_model.classes_)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_score = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    name = f\"{df.status.unique()[i]} (AUC={auc_score:.2f})\"\n",
    "    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines'))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text='False Positive Rate'\n",
    "        ),\n",
    "        constrain='domain'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text='True Positive Rate'\n",
    "        ),\n",
    "        scaleanchor='x',\n",
    "        scaleratio=1\n",
    "    ),\n",
    "    width=900, height=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22760db0",
   "metadata": {
    "id": "22760db0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
